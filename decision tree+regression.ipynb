{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPYGNRR42dbB","outputId":"0b4c376c-8c24-421f-dfed-cadbc200c446"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from itertools import product\n","from sklearn.preprocessing import LabelEncoder\n","pd.set_option('display.max_colwidth', None)  # Show full content in cells\n","# Load the data\n","train_path = '/Users/yingyunqian/Desktop/BT4240 ML/train_data.csv'\n","\n","train_df = pd.read_csv(train_path)\n","\n","# Prepare features and target\n","X = train_df.drop(columns=['Target'])\n","y = train_df['Target']\n","\n","# Extended hyperparameter search space\n","from itertools import product\n","import random\n","\n","max_depth = [3,4, 5,6, 7,8,9, 10,11, 12, None]\n","min_samples_split = [2, 5, 10, 20,25,30,35,40]\n","min_samples_leaf = [1, 2, 3,4, 5,6,7,8,10,11,12]\n","criterion = ['gini', 'entropy']\n","max_features = [None, 'sqrt', 'log2']\n","splitter = ['best', 'random']\n","\n","# Generate all combinations\n","param_grid = list(product(max_depth, min_samples_split, min_samples_leaf, criterion, max_features, splitter))\n","\n","# Shuffle and take 50 random unique combinations\n","random.seed(42)\n","random.shuffle(param_grid)\n","param_grid = param_grid[:13000]  # Experiment with 50 models instead of 20\n","\n","\n","# New suggested parameter sets\n","new_param_suggestions = [\n","    {'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None, 'splitter': 'best'},\n","\n","    # Add more custom combinations as you like\n","]\n","\n","\n","# Convert to tuples (since your loop uses tuples from itertools.product)\n","new_param_grid = [\n","    (\n","        d['max_depth'],\n","        d['min_samples_split'],\n","        d['min_samples_leaf'],\n","        d['criterion'],\n","        d['max_features'],\n","        d['splitter']\n","    )\n","    for d in new_param_suggestions\n","]\n","\n","# Append to existing param_grid\n","param_grid.extend(new_param_grid)\n","# Append to existing param_grid\n","param_grid.extend(new_param_grid)\n","results = []\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","# Update model loop to use the new parameters\n","for i, (depth, min_split, min_leaf, crit, max_feat, split) in enumerate(param_grid):\n","    accuracies, precisions, recalls, f1s = [], [], [], []\n","\n","    for train_idx, val_idx in skf.split(X, y):\n","        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n","        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n","\n","        clf = DecisionTreeClassifier(\n","            max_depth=depth,\n","            min_samples_split=min_split,\n","            min_samples_leaf=min_leaf,\n","            criterion=crit,\n","            max_features=max_feat,\n","            splitter=split,\n","            random_state=42\n","        )\n","\n","        clf.fit(X_train, y_train)\n","        y_pred = clf.predict(X_val)\n","\n","        accuracies.append(accuracy_score(y_val, y_pred))\n","        precisions.append(precision_score(y_val, y_pred))\n","        recalls.append(recall_score(y_val, y_pred))\n","        f1s.append(f1_score(y_val, y_pred))\n","\n","    results.append({\n","        'params': {\n","            'max_depth': depth,\n","            'min_samples_split': min_split,\n","            'min_samples_leaf': min_leaf,\n","            'criterion': crit,\n","            'max_features': max_feat,\n","            'splitter': split\n","        },\n","        'accuracy': np.mean(accuracies),\n","        'precision': np.mean(precisions),\n","        'recall': np.mean(recalls),\n","        'f1_score': np.mean(f1s)\n","    })\n","\n","# Convert results to DataFrame for easy sorting\n","results_df = pd.DataFrame(results)\n","\n","# Sort by F1-score to find best performing models\n","top_5_models = results_df.sort_values(by='f1_score', ascending=False).head(5)\n","\n","print(\"Top 5 Decision Tree Models Based on F1 Score:\\n\")\n","print(top_5_models[['params', 'accuracy', 'precision', 'recall', 'f1_score']])\n","from sklearn.linear_model import LogisticRegression\n","\n","# Logistic Regression Baseline\n","log_acc = []\n","log_prec = []\n","log_rec = []\n","log_f1 = []\n","\n","log_model = LogisticRegression(max_iter=1000, random_state=42)\n","\n","for train_idx, val_idx in skf.split(X, y):\n","    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n","    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n","\n","    log_model.fit(X_train, y_train)\n","    y_pred = log_model.predict(X_val)\n","\n","    log_acc.append(accuracy_score(y_val, y_pred))\n","    log_prec.append(precision_score(y_val, y_pred))\n","    log_rec.append(recall_score(y_val, y_pred))\n","    log_f1.append(f1_score(y_val, y_pred))\n","\n","print(\"ğŸ“Š Logistic Regression Baseline Performance (5-Fold CV):\")\n","print(f\"Accuracy:  {np.mean(log_acc):.4f}\")\n","print(f\"Precision: {np.mean(log_prec):.4f}\")\n","print(f\"Recall:    {np.mean(log_rec):.4f}\")\n","print(f\"F1 Score:  {np.mean(log_f1):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xdztV1ZtVPe","outputId":"cecd6766-4706-4aae-c5a1-f8454a63c6a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Accuracy: 0.8484\n","Precision: 0.7975\n","Recall: 0.6702\n","F1 Score: 0.7283\n","----------------------------------------\n","Fold 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Accuracy: 0.8708\n","Precision: 0.8973\n","Recall: 0.7313\n","F1 Score: 0.8058\n","----------------------------------------\n","Fold 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Accuracy: 0.8368\n","Precision: 0.7565\n","Recall: 0.7300\n","F1 Score: 0.7430\n","----------------------------------------\n","Fold 4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","Accuracy: 0.8611\n","Precision: 0.7660\n","Recall: 0.7742\n","F1 Score: 0.7701\n","----------------------------------------\n","Fold 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","Accuracy: 0.8498\n","Precision: 0.8571\n","Recall: 0.6218\n","F1 Score: 0.7207\n","----------------------------------------\n","Average metrics across all folds:\n","Accuracy: 0.8534\n","Precision: 0.8149\n","Recall: 0.7055\n","F1 Score: 0.7536\n"]}]}]}