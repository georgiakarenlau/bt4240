{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('..\\\\BT4240\\\\train_df.csv')\n",
    "df_test = pd.read_csv('..\\\\BT4240\\\\test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Target', axis=1)\n",
    "y_train = df_train['Target']\n",
    "X_test = df_test.drop('Target',axis=1)\n",
    "y_test = df_test['Target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_split=35,\n",
    "    min_samples_leaf=8,\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "decisionTree_y_pred = clf.predict(X_test)\n",
    "\n",
    "decisionTree_y_proba = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to your training data\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "rf_clf_y_pred = rf_clf.predict(X_test)\n",
    "rf_clf_y_proba = rf_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM model with a linear kernel and probability estimates enabled\n",
    "svm_clf = SVC(C=1, kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get class predictions\n",
    "svm_y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# Get class probability estimates (for class 1)\n",
    "svm_y_proba = svm_clf.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:20:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize the XGBoost model with the given parameters\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.2,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=10,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'  # To suppress warning in newer versions\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get class predictions\n",
    "xgb_y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Get class probabilities for positive class (1)\n",
    "xgb_y_proba = xgb_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Convert features to float32 tensors (required by TensorFlow models)\n",
    "X_train_tensor = tf.convert_to_tensor(X_train.values, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test.values, dtype=tf.float32)\n",
    "\n",
    "# Convert labels to float32 tensors for binary classification\n",
    "y_train_tensor = tf.convert_to_tensor(y_train.values, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test.values, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(256, input_dim=X_train.shape[1], activation='tanh'),\n",
    "        Dense(64, activation='tanh'),\n",
    "        Dense(32, activation='tanh'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Get predicted probabilities and predictions\n",
    "nn_y_proba = model.predict(X_test_tensor).flatten()\n",
    "nn_y_pred = (nn_y_proba >= 0.5).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_proba_array = np.column_stack([\n",
    "    decisionTree_y_proba,\n",
    "    rf_clf_y_proba,   # rf_clf_y_proba\n",
    "    svm_y_proba,\n",
    "    xgb_y_proba,\n",
    "    nn_y_proba\n",
    "])\n",
    "\n",
    "ensemble_proba_df = pd.DataFrame(\n",
    "    ensemble_proba_array,\n",
    "    columns=['DecisionTree', 'RandomForest', 'SVM', 'XGBoost', 'NeuralNet']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Averaging) Evaluation Metrics:\n",
      "Accuracy : 0.8773\n",
      "Precision: 0.8626\n",
      "Recall   : 0.7354\n",
      "F1 Score : 0.7939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Average the probabilities across models\n",
    "ensemble_avg_proba = ensemble_proba_df.mean(axis=1)\n",
    "\n",
    "# Convert probabilities to final predictions using threshold 0.5\n",
    "ensemble_avg_pred = (ensemble_avg_proba >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate against true labels\n",
    "accuracy = accuracy_score(y_test, ensemble_avg_pred)\n",
    "precision = precision_score(y_test, ensemble_avg_pred)\n",
    "recall = recall_score(y_test, ensemble_avg_pred)\n",
    "f1 = f1_score(y_test, ensemble_avg_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Ensemble (Averaging) Evaluation Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Voting) Evaluation Metrics:\n",
      "Accuracy : 0.8758\n",
      "Precision: 0.8599\n",
      "Recall   : 0.7330\n",
      "F1 Score : 0.7914\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "# Convert all model probabilities to binary predictions (threshold = 0.5)\n",
    "ensemble_preds = (ensemble_proba_df >= 0.5).astype(int)\n",
    "\n",
    "# Perform majority voting across rows (axis=1)\n",
    "voting_pred, _ = mode(ensemble_preds, axis=1, keepdims=False)\n",
    "\n",
    "# Evaluate voting ensemble against y_test\n",
    "accuracy = accuracy_score(y_test, voting_pred)\n",
    "precision = precision_score(y_test, voting_pred)\n",
    "recall = recall_score(y_test, voting_pred)\n",
    "f1 = f1_score(y_test, voting_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"Ensemble (Voting) Evaluation Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted probabilities according to f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Weighted Probabilities) Evaluation Metrics:\n",
      "Accuracy : 0.8780\n",
      "Precision: 0.8630\n",
      "Recall   : 0.7377\n",
      "F1 Score : 0.7955\n"
     ]
    }
   ],
   "source": [
    "# Define the weights in the correct order\n",
    "weights = np.array([0.76364, 0.7819, 0.8629, 0.849390, 0.7687])\n",
    "\n",
    "# Apply weighted probability averaging\n",
    "weighted_proba = (ensemble_proba_df.values * weights).sum(axis=1) / weights.sum()\n",
    "\n",
    "# Convert to binary predictions using threshold 0.5\n",
    "weighted_pred = (weighted_proba >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, weighted_pred)\n",
    "precision = precision_score(y_test, weighted_pred)\n",
    "recall = recall_score(y_test, weighted_pred)\n",
    "f1 = f1_score(y_test, weighted_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Ensemble (Weighted Probabilities) Evaluation Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted majority voting according to f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (Weighted Voting on Binary Predictions) Evaluation Metrics:\n",
      "Accuracy : 0.8758\n",
      "Precision: 0.8599\n",
      "Recall   : 0.7330\n",
      "F1 Score : 0.7914\n"
     ]
    }
   ],
   "source": [
    "# Define model weights in order: [Decision Tree, Random Forest, SVM, XGBoost, Neural Net]\n",
    "weights = np.array([0.76364, 0.7819, 0.8629, 0.849390, 0.7687])\n",
    "total_weight = weights.sum()\n",
    "\n",
    "# Convert model probabilities to binary predictions\n",
    "binary_preds = (ensemble_proba_df >= 0.5).astype(int)\n",
    "\n",
    "# Apply weighted voting: multiply predictions by weights\n",
    "weighted_votes = binary_preds.values * weights\n",
    "\n",
    "# Sum the weighted votes across models\n",
    "vote_sums = weighted_votes.sum(axis=1)\n",
    "\n",
    "# Final prediction: class 1 if vote sum >= half the total weight\n",
    "weighted_vote_pred = (vote_sums >= (total_weight / 2)).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, weighted_vote_pred)\n",
    "precision = precision_score(y_test, weighted_vote_pred)\n",
    "recall = recall_score(y_test, weighted_vote_pred)\n",
    "f1 = f1_score(y_test, weighted_vote_pred)\n",
    "\n",
    "# Display\n",
    "print(\"Ensemble (Weighted Voting on Binary Predictions) Evaluation Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
